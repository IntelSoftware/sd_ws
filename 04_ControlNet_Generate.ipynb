{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cbedc7-9702-4b4a-8283-cdc7d6836070",
   "metadata": {},
   "source": [
    "## ControlNet\n",
    "* ControlNet is a type of model for controlling image diffusion models by conditioning the model with an additional input image. There are many types of conditioning inputs (canny edge, user sketching, human pose, depth map, M-LSD, HED, ADE20K) you can use to control a diffusion model. This is hugely useful because it affords you greater control over image generation, making it easier to generate specific images without experimenting with different text prompts or denoising values as much.\n",
    "\n",
    "* [Arxiv](https://arxiv.org/pdf/2302.05543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2f527-6dce-411e-bc86-6128890e8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5ca9d-dee8-4932-87a9-85da22ea76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = load_image(\n",
    "    \"https://img.freepik.com/premium-photo/house-outline-illustration-white-background_1112329-31710.jpg?w=1480\"\n",
    ").resize((1024, 1024))\n",
    "\n",
    "def optimize_pipeline(pipeline):\n",
    "    \"\"\"\n",
    "    Optimizes the model for inference using ipex.\n",
    "\n",
    "    Parameters:\n",
    "    - pipeline: The model pipeline to be optimized.\n",
    "\n",
    "    Returns:\n",
    "    - pipeline: The optimized model pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    for attr in dir(pipeline):\n",
    "        try:\n",
    "            if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                setattr(\n",
    "                    pipeline,\n",
    "                    attr,\n",
    "                    ipex.optimize(\n",
    "                        getattr(pipeline, attr).eval(),\n",
    "                        dtype=pipeline.text_encoder.dtype,\n",
    "                        inplace=True,\n",
    "                    ),\n",
    "                )\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return pipeline\n",
    "\n",
    "image = np.array(original_image)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "canny_image = Image.fromarray(image)\n",
    "\n",
    "image_tensor = torch.tensor(np.array(canny_image)).to(\"xpu\")\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.bfloat16, use_safetensors=True)\n",
    "\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.bfloat16, use_safetensors=True\n",
    ")\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"xpu\")\n",
    "pipe = optimize_pipeline(pipe)\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "with torch.inference_mode():\n",
    "    with torch.xpu.amp.autocast(enabled=True, dtype=torch.bfloat16):\n",
    "        output = pipe(\n",
    "            \"Colorful\", image=canny_image\n",
    "        ).images[0]\n",
    "\n",
    "image_grid = make_image_grid([original_image, canny_image, output], rows=1, cols=3)\n",
    "#image_grid = image_grid.to(\"xpu\")\n",
    "image_grid_np = np.array(image_grid)\n",
    "cv2.imwrite(\"house.png\", image_grid_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch GPU",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
